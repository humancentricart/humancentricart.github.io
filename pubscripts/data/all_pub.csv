ISBN,abstract,address,archivePrefix,authors,booktitle,doi,eprint,issn,journal,month,note,organization,pages,primaryClass,publisher,title,url,volume,year
979-8-89176-256-5,"Memorization is a fundamental ability of Transformer-based Large Language Models, achieved through learning. In this position/theory paper, we propose a paradigm shift by designing an architecture to memorize text directly, bearing in mind the principle that memorization precedes learning. We introduce MeMo, a novel architecture for language modeling that explicitly memorizes sequences of tokens in layered associative memories. By design, MeMo offers transparency and the possibility of model editing, including forgetting texts. We experimented with the MeMo architecture, showing the memorization power of the one-layer and the multi-layer configurations.","Vienna, Austria",,"Zanzotto, Fabio Massimo; Ruzzetti, Elena Sofia; Xompero, Giancarlo A.; Ranaldi, Leonardo; Venditti, Davide; Ranaldi, Federico; Giannone, Cristina; Favalli, Andrea; Romagnoli, Raniero",Findings of the Association for Computational Linguistics: ACL 2025,,,,,July,,,15169--15180,,Association for Computational Linguistics,Position Paper: {M}e{M}o: Towards Language Models with Associative Memory Mechanisms,https://aclanthology.org/2025.findings-acl.785/,,2025
979-8-89176-251-0,"Large Language Models (LLMs) memorize, and thus, among huge amounts of uncontrolled data, may memorize Personally Identifiable Information (PII), which should not be stored and, consequently, not leaked. In this paper, we introduce Private Memorization Editing (PME), an approach for preventing private data leakage that turns an apparent limitation, that is, the LLMs' memorization ability, into a powerful privacy defense strategy. While attacks against LLMs have been performed exploiting previous knowledge regarding their training data, our approach aims to exploit the same kind of knowledge in order to make a model more robust. We detect a memorized PII and then mitigate the memorization of PII by editing a model knowledge of its training data. We verify that our procedure does not affect the underlying language model while making it more robust against privacy Training Data Extraction attacks. We demonstrate that PME can effectively reduce the number of leaked PII in a number of configurations, in some cases even reducing the accuracy of the privacy attacks to zero.","Vienna, Austria",,"Ruzzetti, Elena Sofia; Xompero, Giancarlo A.; Venditti, Davide; Zanzotto, Fabio Massimo",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,,,,July,,,16572--16592,,Association for Computational Linguistics,Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models,https://aclanthology.org/2025.acl-long.810/,,2025
979-8-89176-251-0,"Reasoning is an intricate process that transcends both language and vision; yet, despite its inherently modality-agnostic nature, develop-ing effective multilingual and multimodal reasoning capabilities remains a substantial challenge for Multimodal Large Language Models (MLLMs). They struggle to activate complex reasoning behaviours, delivering step-wise explanation, questioning and reflection, particularly in multilingual settings where high-quality supervision across languages is lacking. Recent works have introduced eclectic strategies to enhance MLLMs' reasoning; however, they remain related to a single language.To make MLLMs' reasoning capabilities aligned among languages and improve modality performances, we propose R2-MultiOmnia, a modular approach that instructs the models to abstract key elements of the reasoning process and then refine reasoning trajectories via self-correction. Specifically, we instruct the models producing multimodal synthetic resources by bridging modalities and then self-improving their capabilities. To stabilise learning and the reasoning processes structure, we propose Curriculum Learning Reasoning Stabilisation with structured output rewards to gradually refine the models' capabilities to learn and deliver robust reasoning processes. Experiments show that R2-MultiOmnia improves multimodal reasoning, gets aligned performances among the languages approaching strong models.","Vienna, Austria",,"Ranaldi, Leonardo; Ranaldi, Federico; Pucci, Giulia",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,,,,July,,,8220--8234,,Association for Computational Linguistics,{R}2-{M}ulti{O}mnia: Leading Multilingual Multimodal Reasoning via Self-Training,https://aclanthology.org/2025.acl-long.402/,,2025
,"We introduce the concept of protoknowledge to formalize and measure how sequences of tokens encoding Knowledge Graphs are internalized during pretraining and utilized at inference time by Large Language Models (LLMs). Indeed, LLMs have demonstrated the ability to memorize vast amounts of token sequences during pretraining, and a central open question is how they leverage this memorization as reusable knowledge through generalization. We then categorize protoknowledge into lexical, hierarchical, and topological forms, varying on the type of knowledge that needs to be activated. We measure protoknowledge through Knowledge Activation Tasks (KATs), analyzing its general properties such as semantic bias. We then investigate the impact of protoknowledge on Text-to-SPARQL performance by varying prompting strategies depending on input conditions. To this end, we adopt a novel analysis framework that assesses whether model predictions align with the successful activation of the relevant protoknowledge for each query. This methodology provides a practical tool to explore Semantic-Level Data Contamination and serves as an effective strategy for Closed-Pretraining models.",,arXiv,"Ranaldi, Federico; Zugarini, Andrea; Ranaldi, Leonardo; Zanzotto, Fabio Massimo",,,2505.15501,,,,,,,cs.CL,,Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs,https://arxiv.org/abs/2505.15501,,2025
,,,,"Miranda, Michele; Ruzzetti, Elena Sofia; Santilli, Andrea; Zanzotto, Fabio Massimo; Brati{\`e}res, S{\'e}bastien; Rodol{\`a}, Emanuele",,,,2835-8856,Transactions on Machine Learning Research,,,,,,,Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions,https://openreview.net/forum?id=Ss9MTTN7OL,,2025
,,,,"Venditti, Davide; Ruzzetti, Elena Sofia; Xompero, Giancarlo A; Giannone, Cristina; Favalli, Andrea; Romagnoli, Raniero; Zanzotto, Fabio Massimo",,,,,arXiv preprint arXiv:2406.18221,,,,,,,Enhancing Data Privacy in Large Language Models through Private Association Editing,,,2024
,,,,"Ruzzetti, Elena Sofia; Venditti, Davide; Zanzotto, Fabio Massimo; Fallucchi, Francesca",,,,,IEEE Access,,,,158207--158214,,IEEE,Using distributional models for studying the influence of school textbooks in children bias,,12,2024
,,,,"Ruzzetti, Elena Sofia; Ranaldi, Federico; Onorati, Dario; Venditti, Davide; Ranaldi, Leonardo; Caselli, Tommaso; Zanzotto, Fabio Massimo","CLiC-it 2024: Tenth Italian Conference on Computational Linguistics,",,,,,,,,,,,Assessing the Asymmetric Behaviour of Italian Large Language Models across Different Syntactic Structures,,,2024
,"Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training are emerging as the next big revolution in natural language processing and understanding. These CtB-LLMs are democratizing access to trainable Very Large-Language Models (VLLMs) and, thus, may represent the building blocks of many NLP systems solving downstream tasks. Hence, a little or a large bias in CtB-LLMs may cause huge harm. In this paper, we performed a large investigation of the bias of three families of CtB-LLMs, and we showed that debiasing techniques are effective and usable. Indeed, according to current tests, the LLaMA and the OPT families have an important bias in gender, race, religion, and profession. In contrast to the analysis for other LMMs, we discovered that bias depends not on the number of parameters but on the perplexity. Finally, the debiasing of OPT using LORA reduces bias up to 4.12 points in the normalized stereotype score.","Mexico City, Mexico",,"Ranaldi, Leonardo; Ruzzetti, Elena Sofia; Venditti, Davide; Onorati, Dario; Zanzotto, Fabio Massimo",Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024),10.18653/v1/2024.starsem-1.30,,,,June,,,372--384,,Association for Computational Linguistics,A Trip Towards Fairness: Bias and De-Biasing in Large Language Models,https://aclanthology.org/2024.starsem-1.30/,,2024
,"Reasoning methods, best exemplified by the well-known Chain-of-Thought (CoT), empower the reasoning abilities of Large Language Models (LLMs) by eliciting them to solve complex tasks in a step-by-step manner. Although they are achieving significant success, the ability to deliver multi-step reasoning remains limited to English because of the imbalance in the distribution of pre-training data, which makes other languages a barrier. In this paper, we propose Cross-lingual Tree-of-Thoughts (Cross-ToT), a method for aligning Cross-lingual CoT reasoning across languages. The proposed method, through a self-consistent cross-lingual prompting mechanism inspired by the Tree-of-Thoughts approach, provides multi-step reasoning paths in different languages that, during the steps, lead to the final solution. Experimental evaluations show that our method significantly outperforms existing prompting methods by reducing the number of interactions and achieving state-of-the-art performance.","Mexico City, Mexico",,"Ranaldi, Leonardo; Pucci, Giulia; Ranaldi, Federico; Ruzzetti, Elena Sofia; Zanzotto, Fabio Massimo",Findings of the Association for Computational Linguistics: NAACL 2024,10.18653/v1/2024.findings-naacl.78,,,,June,,,1229--1241,,Association for Computational Linguistics,A Tree-of-Thoughts to Broaden Multi-step Reasoning across Languages,https://aclanthology.org/2024.findings-naacl.78/,,2024
,,,,"Ranaldi, Leonardo; Pucci, Giulia; Ranaldi, Federico; Ruzzetti, Elena Sofia; Zanzotto, Fabio Massimo",Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024),,,,,,,,781--795,,,The limits of Italian in Reasoning Tasks,,,2024
,,,,"Ranaldi, Federico; Ruzzetti, Elena Sofia; Onorati, Dario; Zanzotto, Fabio Massimo; Ranaldi, Leonardo",Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024),,,,,,,,1176--1183,,,Termite Italian Text-to-SQL: A CALAMITA Challenge,,,2024
,,,,"Ranaldi, Federico; Ruzzetti, Elena Sofia; Onorati, Dario; Ranaldi, Leonardo; Giannone, Cristina; Favalli, Andrea; Romagnoli, Raniero; Zanzotto, Fabio Massimo",,,,,Findings of the Association for Computational Linguistics: ACL 2024,,,,13909--13920,,,Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL translation,https://aclanthology.org/2024.findings-acl.827/,,2024
,,,,"Onorati, Dario; Venditti, Davide; Ruzzetti, Elena Sofia; Ranaldi, Federico; Ranaldi, Leonardo; Zanzotto, Fabio Massimo",Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024),,,,,,,,679--706,,,Measuring bias in Instruction-Following models with ItaP-AT for the Italian Language,,,2024
,"The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices.",Singapore,,"Ruzzetti, Elena Sofia; Ranaldi, Federico; Logozzo, Felicia; Mastromattei, Michele; Ranaldi, Leonardo; Zanzotto, Fabio Massimo",Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.963,,,,December,,,14447--14461,,Association for Computational Linguistics,Exploring Linguistic Properties of Monolingual {BERT}s with Typological Classification among Languages,https://aclanthology.org/2023.findings-emnlp.963/,,2023
,,,,"Ruzzetti, Elena Sofia; Onorati, Dario; Ranaldi, Leonardo; Venditti, Davide; Zanzotto, Fabio Massimo",CLiC-it 2023: 9th Italian Conference on Computational Linguistics,,,,,,,CEUR-WS,,,,Investigating Gender Bias in Large Language Models for the Italian Language,,3596,2023
,"Large Language Models (LLMs) are impressive machines with the ability to memorize, possibly generalized learning examples. We present here a small, focused contribution to the analysis of the interplay between memorization and performance of BERT in downstream tasks. We propose PreCog, a measure for evaluating memorization from pre-training, and we analyze its correlation with the BERT{'}s performance. Our experiments show that highly memorized examples are better classified, suggesting memorization is an essential key to success for BERT.","Varna, Bulgaria",,"Ranaldi, Leonardo; Ruzzetti, Elena Sofia; Zanzotto, Fabio Massimo",Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing,,,,,September,,,961--967,,"INCOMA Ltd., Shoumen, Bulgaria",PreCog: Exploring the Relation between Memorization and Performance in Pre-trained Language Models,https://aclanthology.org/2023.ranlp-1.103/,,2023
,,,,"Ranaldi, Leonardo; Pucci, Giulia; Ruzzetti, Elena Sofia; Zanzotto, Fabio Massimo; Freitas, Andr{\'e}",Proceedings of the 9th Italian Conference on Computational Linguistics (CLiC-it 2023),,,,,,,,557--561,,,Teasing LLMs adapted to Italian,,,2023
,"Pre-trained Transformers are challenging human performances in many Natural Language Processing tasks. The massive datasets used for pre-training seem to be the key to their success on existing tasks. In this paper, we explore how a range of pre-trained natural language understanding models performs on definitely unseen sentences provided by classification tasks over a DarkNet corpus. Surprisingly, results show that syntactic and lexical neural networks perform on par with pre-trained Transformers even after fine-tuning. Only after what we call extreme domain adaptation, that is, retraining with the masked language model task on all the novel corpus, pre-trained Transformers reach their standard high results. This suggests that huge pre-training corpora may give Transformers unexpected help since they are exposed to many of the possible sentences.","Varna, Bulgaria",,"Ranaldi, Leonardo; Nourbakhsh, Aria; Ruzzetti, Elena Sofia; Patrizi, Arianna; Onorati, Dario; Mastromattei, Michele; Fallucchi, Francesca; Zanzotto, Fabio Massimo",Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing,,,,,September,,,949--960,,"INCOMA Ltd., Shoumen, Bulgaria",The Dark Side of the Language: Pre-trained Transformers in the {D}ark{N}et,https://aclanthology.org/2023.ranlp-1.102/,,2023
,,,,"Ranaldi, Federico; Ruzzetti, Elena Sofia; Ranaldi, Leonardo; Venditti, Davide; Giannone, Cristina; Favalli, Andrea; Romagnoli, Raniero; Zanzotto, Fabio Massimo",Italian Conference on Computational Linguistics 2023,,,,,,,,,,,Prompting LLMs in Italian language for Text-to-SQL translation,,,2023
,"Instruction-Following Language Models (IFLMs) are promising and versatile tools for solving many downstream, information-seeking tasks. Given their success, there is an urgent need to have a shared resource to determine whether existing and new IFLMs are prone to produce biased language interactions. In this paper, we propose Prompt Association Test (P-AT): a new resource for testing the presence of social biases in IFLMs. P-AT stems from WEAT (Caliskan et al., 2017) and generalizes the notion of measuring social biases to IFLMs. Basically, we cast WEAT word tests in promptized classification tasks, and we associate a metric - the bias score. Our resource consists of 2310 prompts. We then experimented with several families of IFLMs discovering gender and race biases in all the analyzed models. We expect P-AT to be an important tool for quantifying bias across different dimensions and, therefore, for encouraging the creation of fairer IFLMs before their distortions have consequences in the real world.",Singapore,,"Onorati, Dario; Ruzzetti, Elena Sofia; Venditti, Davide; Ranaldi, Leonardo; Zanzotto, Fabio Massimo",Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.539,,,,December,,,8006--8034,,Association for Computational Linguistics,Measuring bias in Instruction-Following models with {P}-{AT},https://aclanthology.org/2023.findings-emnlp.539/,,2023
,,,,"Onorati, Dario; Ranaldi, Leonardo; Nourbakhsh, Aria; Patrizi, Arianna; Ruzzetti, Elena Sofia; Mastromattei, Michele; Fallucchi, Francesca; Zanzotto, Fabio Massimo",2023 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),,,,,,,IEEE,111--118,,,The Dark Side of the Language: Syntax-Based Neural Networks Rivaling Transformers in Definitely Unseen Sentences,,,2023
,"Word embeddings are powerful dictionaries, which may easily capture language variations. However, these dictionaries fail to give sense to rare words, which are surprisingly often covered by traditional dictionaries. In this paper, we propose to use definitions retrieved in traditional dictionaries to produce word embeddings for rare words. For this purpose, we introduce two methods: Definition Neural Network (DefiNNet) and Define BERT (DefBERT). In our experiments, DefiNNet and DefBERT significantly outperform state-of-the-art as well as baseline methods devised for producing embeddings of unknown words. In fact, DefiNNet significantly outperforms FastText, which implements a method for the same task-based on n-grams, and DefBERT significantly outperforms the BERT method for OOV words. Then, definitions in traditional dictionaries are useful to build word embeddings for rare words.","Dublin, Ireland",,"Ruzzetti, Elena Sofia; Ranaldi, Leonardo; Mastromattei, Michele; Fallucchi, Francesca; Scarpato, Noemi; Zanzotto, Fabio Massimo",Findings of the Association for Computational Linguistics: ACL 2022,10.18653/v1/2022.findings-acl.208,,,,May,,,2651--2662,,Association for Computational Linguistics,Lacking the Embedding of a Word? Look it up into a Traditional Dictionary,https://aclanthology.org/2022.findings-acl.208/,,2022
,,,,"Ranaldi, Leonardo; Mastromattei, Michele; Onorati, Dario; Fallucchi, Francesca; others",CEUR WORKSHOP PROCEEDINGS,,,,,,,CEUR-WS,,,,KERMIT for Sentiment Analysis in Italian Healthcare Reviews,,3033,2022
