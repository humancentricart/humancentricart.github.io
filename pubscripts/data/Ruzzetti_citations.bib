@inproceedings{ruzzetti-etal-2022-lacking,
    title = "Lacking the Embedding of a Word? Look it up into a Traditional Dictionary",
    author = "Ruzzetti, Elena Sofia  and
      Ranaldi, Leonardo  and
      Mastromattei, Michele  and
      Fallucchi, Francesca  and
      Scarpato, Noemi  and
      Zanzotto, Fabio Massimo",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.208/",
    doi = "10.18653/v1/2022.findings-acl.208",
    pages = "2651--2662",
    abstract = "Word embeddings are powerful dictionaries, which may easily capture language variations. However, these dictionaries fail to give sense to rare words, which are surprisingly often covered by traditional dictionaries. In this paper, we propose to use definitions retrieved in traditional dictionaries to produce word embeddings for rare words. For this purpose, we introduce two methods: Definition Neural Network (DefiNNet) and Define BERT (DefBERT). In our experiments, DefiNNet and DefBERT significantly outperform state-of-the-art as well as baseline methods devised for producing embeddings of unknown words. In fact, DefiNNet significantly outperforms FastText, which implements a method for the same task-based on n-grams, and DefBERT significantly outperforms the BERT method for OOV words. Then, definitions in traditional dictionaries are useful to build word embeddings for rare words."
}

@inproceedings{ranaldi-etal-2024-trip,
    title = "A Trip Towards Fairness: Bias and De-Biasing in Large Language Models",
    author = "Ranaldi, Leonardo  and
      Ruzzetti, Elena Sofia  and
      Venditti, Davide  and
      Onorati, Dario  and
      Zanzotto, Fabio Massimo",
    editor = "Bollegala, Danushka  and
      Shwartz, Vered",
    booktitle = "Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.starsem-1.30/",
    doi = "10.18653/v1/2024.starsem-1.30",
    pages = "372--384",
    abstract = "Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training are emerging as the next big revolution in natural language processing and understanding. These CtB-LLMs are democratizing access to trainable Very Large-Language Models (VLLMs) and, thus, may represent the building blocks of many NLP systems solving downstream tasks. Hence, a little or a large bias in CtB-LLMs may cause huge harm. In this paper, we performed a large investigation of the bias of three families of CtB-LLMs, and we showed that debiasing techniques are effective and usable. Indeed, according to current tests, the LLaMA and the OPT families have an important bias in gender, race, religion, and profession. In contrast to the analysis for other LMMs, we discovered that bias depends not on the number of parameters but on the perplexity. Finally, the debiasing of OPT using LORA reduces bias up to 4.12 points in the normalized stereotype score."
}

@inproceedings{ranaldi2022kermit,
  title={KERMIT for Sentiment Analysis in Italian Healthcare Reviews},
  author={Ranaldi, Leonardo and Mastromattei, Michele and Onorati, Dario and Fallucchi, Francesca and others},
  booktitle={CEUR WORKSHOP PROCEEDINGS},
  volume={3033},
  year={2022},
  organization={CEUR-WS}
}

@inproceedings{ranaldi-etal-2023-precog,
    title = "PreCog: Exploring the Relation between Memorization and Performance in Pre-trained Language Models",
    author = "Ranaldi, Leonardo  and
      Ruzzetti, Elena Sofia  and
      Zanzotto, Fabio Massimo",
    editor = "Mitkov, Ruslan  and
      Angelova, Galia",
    booktitle = "Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing",
    month = sep,
    year = "2023",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd., Shoumen, Bulgaria",
    url = "https://aclanthology.org/2023.ranlp-1.103/",
    pages = "961--967",
    abstract = "Large Language Models (LLMs) are impressive machines with the ability to memorize, possibly generalized learning examples. We present here a small, focused contribution to the analysis of the interplay between memorization and performance of BERT in downstream tasks. We propose PreCog, a measure for evaluating memorization from pre-training, and we analyze its correlation with the BERT{'}s performance. Our experiments show that highly memorized examples are better classified, suggesting memorization is an essential key to success for BERT."
}

@inproceedings{ranaldi-etal-2023-dark,
    title = "The Dark Side of the Language: Pre-trained Transformers in the {D}ark{N}et",
    author = "Ranaldi, Leonardo  and
      Nourbakhsh, Aria  and
      Ruzzetti, Elena Sofia  and
      Patrizi, Arianna  and
      Onorati, Dario  and
      Mastromattei, Michele  and
      Fallucchi, Francesca  and
      Zanzotto, Fabio Massimo",
    editor = "Mitkov, Ruslan  and
      Angelova, Galia",
    booktitle = "Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing",
    month = sep,
    year = "2023",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd., Shoumen, Bulgaria",
    url = "https://aclanthology.org/2023.ranlp-1.102/",
    pages = "949--960",
    abstract = "Pre-trained Transformers are challenging human performances in many Natural Language Processing tasks. The massive datasets used for pre-training seem to be the key to their success on existing tasks. In this paper, we explore how a range of pre-trained natural language understanding models performs on definitely unseen sentences provided by classification tasks over a DarkNet corpus. Surprisingly, results show that syntactic and lexical neural networks perform on par with pre-trained Transformers even after fine-tuning. Only after what we call extreme domain adaptation, that is, retraining with the masked language model task on all the novel corpus, pre-trained Transformers reach their standard high results. This suggests that huge pre-training corpora may give Transformers unexpected help since they are exposed to many of the possible sentences."
}

@inproceedings{ruzzetti-etal-2023-exploring,
    title = "Exploring Linguistic Properties of Monolingual {BERT}s with Typological Classification among Languages",
    author = "Ruzzetti, Elena Sofia  and
      Ranaldi, Federico  and
      Logozzo, Felicia  and
      Mastromattei, Michele  and
      Ranaldi, Leonardo  and
      Zanzotto, Fabio Massimo",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.963/",
    doi = "10.18653/v1/2023.findings-emnlp.963",
    pages = "14447--14461",
    abstract = "The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices."
}

@inproceedings{onorati-etal-2023-measuring,
    title = "Measuring bias in Instruction-Following models with {P}-{AT}",
    author = "Onorati, Dario  and
      Ruzzetti, Elena Sofia  and
      Venditti, Davide  and
      Ranaldi, Leonardo  and
      Zanzotto, Fabio Massimo",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.539/",
    doi = "10.18653/v1/2023.findings-emnlp.539",
    pages = "8006--8034",
    abstract = "Instruction-Following Language Models (IFLMs) are promising and versatile tools for solving many downstream, information-seeking tasks. Given their success, there is an urgent need to have a shared resource to determine whether existing and new IFLMs are prone to produce biased language interactions. In this paper, we propose Prompt Association Test (P-AT): a new resource for testing the presence of social biases in IFLMs. P-AT stems from WEAT (Caliskan et al., 2017) and generalizes the notion of measuring social biases to IFLMs. Basically, we cast WEAT word tests in promptized classification tasks, and we associate a metric - the bias score. Our resource consists of 2310 prompts. We then experimented with several families of IFLMs discovering gender and race biases in all the analyzed models. We expect P-AT to be an important tool for quantifying bias across different dimensions and, therefore, for encouraging the creation of fairer IFLMs before their distortions have consequences in the real world."
}

@inproceedings{onorati2023dark,
  title={The Dark Side of the Language: Syntax-Based Neural Networks Rivaling Transformers in Definitely Unseen Sentences},
  author={Onorati, Dario and Ranaldi, Leonardo and Nourbakhsh, Aria and Patrizi, Arianna and Ruzzetti, Elena Sofia and Mastromattei, Michele and Fallucchi, Francesca and Zanzotto, Fabio Massimo},
  booktitle={2023 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)},
  pages={111--118},
  year={2023},
  organization={IEEE}
}

@inproceedings{ruzzetti2023investigating,
  title={Investigating Gender Bias in Large Language Models for the Italian Language},
  author={Ruzzetti, Elena Sofia and Onorati, Dario and Ranaldi, Leonardo and Venditti, Davide and Zanzotto, Fabio Massimo},
  booktitle={CLiC-it 2023: 9th Italian Conference on Computational Linguistics},
  volume={3596},
  year={2023},
  organization={CEUR-WS}
}

@inproceedings{ranaldi2023prompting,
  title={Prompting LLMs in Italian language for Text-to-SQL translation},
  author={Ranaldi, Federico and Ruzzetti, Elena Sofia and Ranaldi, Leonardo and Venditti, Davide and Giannone, Cristina and Favalli, Andrea and Romagnoli, Raniero and Zanzotto, Fabio Massimo},
  booktitle={Italian Conference on Computational Linguistics 2023},
  year={2023}
}

@inproceedings{ranaldi2023teasing,
  title={Teasing LLMs adapted to Italian},
  author={Ranaldi, Leonardo and Pucci, Giulia and Ruzzetti, Elena Sofia and Zanzotto, Fabio Massimo and Freitas, Andr{\'e}},
  booktitle={Proceedings of the 9th Italian Conference on Computational Linguistics (CLiC-it 2023)},
  pages={557--561},
  year={2023}
}

@article{ranaldi2024investigating,
  title={Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL translation},
  author={Ranaldi, Federico and Ruzzetti, Elena Sofia and Onorati, Dario and Ranaldi, Leonardo and Giannone, Cristina and Favalli, Andrea and Romagnoli, Raniero and Zanzotto, Fabio Massimo},
  journal={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={13909--13920},
  url={https://aclanthology.org/2024.findings-acl.827/},
  year={2024}
}

@article{ruzzetti2024using,
  title={Using distributional models for studying the influence of school textbooks in children bias},
  author={Ruzzetti, Elena Sofia and Venditti, Davide and Zanzotto, Fabio Massimo and Fallucchi, Francesca},
  journal={IEEE Access},
  volume={12},
  pages={158207--158214},
  year={2024},
  publisher={IEEE}
}

@article{venditti2024enhancing,
  title={Enhancing Data Privacy in Large Language Models through Private Association Editing},
  author={Venditti, Davide and Ruzzetti, Elena Sofia and Xompero, Giancarlo A and Giannone, Cristina and Favalli, Andrea and Romagnoli, Raniero and Zanzotto, Fabio Massimo},
  journal={arXiv preprint arXiv:2406.18221},
  year={2024}
}

@article{
  miranda2025preserving,
  title={Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions},
  author={Michele Miranda and Elena Sofia Ruzzetti and Andrea Santilli and Fabio Massimo Zanzotto and S{\'e}bastien Brati{\`e}res and Emanuele Rodol{\`a}},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2025},
  url={https://openreview.net/forum?id=Ss9MTTN7OL},
  note={}
}

@inproceedings{ranaldi-etal-2024-tree,
    title = "A Tree-of-Thoughts to Broaden Multi-step Reasoning across Languages",
    author = "Ranaldi, Leonardo  and
      Pucci, Giulia  and
      Ranaldi, Federico  and
      Ruzzetti, Elena Sofia  and
      Zanzotto, Fabio Massimo",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.78/",
    doi = "10.18653/v1/2024.findings-naacl.78",
    pages = "1229--1241",
    abstract = "Reasoning methods, best exemplified by the well-known Chain-of-Thought (CoT), empower the reasoning abilities of Large Language Models (LLMs) by eliciting them to solve complex tasks in a step-by-step manner. Although they are achieving significant success, the ability to deliver multi-step reasoning remains limited to English because of the imbalance in the distribution of pre-training data, which makes other languages a barrier. In this paper, we propose Cross-lingual Tree-of-Thoughts (Cross-ToT), a method for aligning Cross-lingual CoT reasoning across languages. The proposed method, through a self-consistent cross-lingual prompting mechanism inspired by the Tree-of-Thoughts approach, provides multi-step reasoning paths in different languages that, during the steps, lead to the final solution. Experimental evaluations show that our method significantly outperforms existing prompting methods by reducing the number of interactions and achieving state-of-the-art performance."
}

@inproceedings{ranaldi2024termite,
  title={Termite Italian Text-to-SQL: A CALAMITA Challenge},
  author={Ranaldi, Federico and Ruzzetti, Elena Sofia and Onorati, Dario and Zanzotto, Fabio Massimo and Ranaldi, Leonardo},
  booktitle={Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024)},
  pages={1176--1183},
  year={2024}
}

@inproceedings{onorati2024measuring,
  title={Measuring bias in Instruction-Following models with ItaP-AT for the Italian Language},
  author={Onorati, Dario and Venditti, Davide and Ruzzetti, Elena Sofia and Ranaldi, Federico and Ranaldi, Leonardo and Zanzotto, Fabio Massimo},
  booktitle={Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024)},
  pages={679--706},
  year={2024}
}

@inproceedings{ruzzetti2024assessing,
  title={Assessing the Asymmetric Behaviour of Italian Large Language Models across Different Syntactic Structures},
  author={Ruzzetti, Elena Sofia and Ranaldi, Federico and Onorati, Dario and Venditti, Davide and Ranaldi, Leonardo and Caselli, Tommaso and Zanzotto, Fabio Massimo},
  booktitle={CLiC-it 2024: Tenth Italian Conference on Computational Linguistics,},
  year={2024}
}

@inproceedings{ranaldi2024limits,
  title={The limits of Italian in Reasoning Tasks},
  author={Ranaldi, Leonardo and Pucci, Giulia and Ranaldi, Federico and Ruzzetti, Elena Sofia and Zanzotto, Fabio Massimo},
  booktitle={Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024)},
  pages={781--795},
  year={2024}
}

@inproceedings{zanzotto-etal-2025-position,
    title = "Position Paper: {M}e{M}o: Towards Language Models with Associative Memory Mechanisms",
    author = "Zanzotto, Fabio Massimo  and
      Ruzzetti, Elena Sofia  and
      Xompero, Giancarlo A.  and
      Ranaldi, Leonardo  and
      Venditti, Davide  and
      Ranaldi, Federico  and
      Giannone, Cristina  and
      Favalli, Andrea  and
      Romagnoli, Raniero",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.785/",
    pages = "15169--15180",
    ISBN = "979-8-89176-256-5",
    abstract = "Memorization is a fundamental ability of Transformer-based Large Language Models, achieved through learning. In this position/theory paper, we propose a paradigm shift by designing an architecture to memorize text directly, bearing in mind the principle that memorization precedes learning. We introduce MeMo, a novel architecture for language modeling that explicitly memorizes sequences of tokens in layered associative memories. By design, MeMo offers transparency and the possibility of model editing, including forgetting texts. We experimented with the MeMo architecture, showing the memorization power of the one-layer and the multi-layer configurations."
}

@inproceedings{ruzzetti-etal-2025-private,
    title = "Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models",
    author = "Ruzzetti, Elena Sofia  and
      Xompero, Giancarlo A.  and
      Venditti, Davide  and
      Zanzotto, Fabio Massimo",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.810/",
    pages = "16572--16592",
    ISBN = "979-8-89176-251-0",
    abstract = "Large Language Models (LLMs) memorize, and thus, among huge amounts of uncontrolled data, may memorize Personally Identifiable Information (PII), which should not be stored and, consequently, not leaked. In this paper, we introduce Private Memorization Editing (PME), an approach for preventing private data leakage that turns an apparent limitation, that is, the LLMs' memorization ability, into a powerful privacy defense strategy. While attacks against LLMs have been performed exploiting previous knowledge regarding their training data, our approach aims to exploit the same kind of knowledge in order to make a model more robust. We detect a memorized PII and then mitigate the memorization of PII by editing a model knowledge of its training data. We verify that our procedure does not affect the underlying language model while making it more robust against privacy Training Data Extraction attacks. We demonstrate that PME can effectively reduce the number of leaked PII in a number of configurations, in some cases even reducing the accuracy of the privacy attacks to zero."
}